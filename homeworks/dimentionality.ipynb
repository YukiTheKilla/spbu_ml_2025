{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes, fetch_openml,load_iris,fetch_california_housing\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, RFE, SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "RepeatedStratifiedKFold, \n",
    "cross_val_score, \n",
    "train_test_split, \n",
    "GridSearchCV,\n",
    "cross_val_predict, \n",
    "learning_curve, \n",
    "validation_curve)\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error,zero_one_loss, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from os.path import join as pjoin\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "#sharper plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV,\n",
    "                                  SGDClassifier)\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Acer\\Desktop\\spbu_ml_2025\\data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filename, size=64):\n",
    "    with Image.open(filename) as img:\n",
    "        # Convert to grayscale and resize\n",
    "        img = img.convert('L').resize((size, size))\n",
    "        \n",
    "        # Convert to numpy array with channel dimension\n",
    "        arr = np.array(img, dtype=np.uint8)[..., np.newaxis]\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m all_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(cats_path ) \n\u001b[32m      8\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m f.lower().endswith((\u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m'\u001b[39m))]\n\u001b[32m      9\u001b[39m processed = []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     11\u001b[39m     processed.append(process_image(os.path.join(cats_path, filename)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Acer\\.conda\\envs\\ml_2025\\Lib\\random.py:430\u001b[39m, in \u001b[36mRandom.sample\u001b[39m\u001b[34m(self, population, k, counts)\u001b[39m\n\u001b[32m    428\u001b[39m randbelow = \u001b[38;5;28mself\u001b[39m._randbelow\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= k <= n:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSample larger than population or is negative\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    431\u001b[39m result = [\u001b[38;5;28;01mNone\u001b[39;00m] * k\n\u001b[32m    432\u001b[39m setsize = \u001b[32m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "cats_path = os.path.join(data_path, \"PetImages\")\n",
    "image_shape = (64, 64)\n",
    "rows, cols = 2, 4\n",
    "n_samples = rows * cols\n",
    "\n",
    "all_files = [f for f in os.listdir(cats_path ) \n",
    "                if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "processed = []\n",
    "for filename in random.sample(all_files, 120):\n",
    "    processed.append(process_image(os.path.join(cats_path, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
